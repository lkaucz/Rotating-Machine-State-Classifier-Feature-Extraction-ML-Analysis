# -*- coding: utf-8 -*-
"""Generating df_experiments.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W0QhUbrkBDcgsIpWQspvWuL3iuqRj8Kf

## Generating df_Experiments
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sb
from google.colab import drive
from sklearn.preprocessing import LabelEncoder
import scipy.stats
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from scipy.fft import fft, fftfreq
from scipy.signal import find_peaks
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
import os

encode = LabelEncoder()

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

def visualizacao_tempo_freq(tabela, title='Posição X Tempo e Amplitude X Frequência'):
    fig, axs = plt.subplots(3, 2, figsize=(15, 8))
    fig.suptitle(title, fontsize=16)

    N = len(tabela.index)
    tempo = np.linspace(0, 10, N)
    freq = np.fft.fftfreq(N, 1/1000)

    colunas_aceleracao = [
        'Eixo_x', 'Eixo_y', 'Eixo_z'
    ]

    for i, coluna in enumerate(colunas_aceleracao):
        # Plotar no domínio do tempo
        axs[i, 0].plot(tempo, tabela[coluna])
        axs[i, 0].set_title(f'Aceleração {coluna}')
        axs[i, 0].set_xlabel('Tempo [s]')
        axs[i, 0].set_ylabel('Aceleração')

        # Plotar no domínio da frequência
        fft_result = np.abs(np.fft.fft(tabela[coluna])) / N
        axs[i, 1].plot(freq[0:int(N/2)], fft_result[:N//2], 'k')

        axs[i, 1].set_title(f'FFT da Aceleração {coluna}')
        axs[i, 1].set_xlabel('Frequência [Hz]')
        axs[i, 1].set_ylabel('Amplitude')

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()
    print("Gráficos de Posição X Tempo e Amplitude X Frequência do dataset de exemplo:")

def filtrar_sinais(df_original):

    tempo = df_original["Tempo[s]"].to_numpy()
    df_filtrado = df_original.copy()
    N = len(df_original.index)
    for coluna in df_original.columns[1:]:

        sinal = df_original[coluna].to_numpy().copy()

        # Calcular a FFT
        fft_resultado = np.fft.fft(df_original[coluna]) / N
        frequencias = np.fft.fftfreq(len(sinal), 1/1000)

        # Encontrar o pico máximo nas amplitudes da FFT
        pico_maximo = np.max(np.abs(fft_resultado))

        # Aplicar o filtro: Se o valor for menor que 5% do pico máximo e frequência <= 500rad/s, definir como 0
        fft_resultado = [0 if (np.abs(amp) <= 0.1 * pico_maximo) or (freq >= 500) or (freq < 0) else amp for amp, freq in zip(fft_resultado, frequencias)]

        # for i in range(len(fft_resultado)-1):
        #   if fft_resultado[i-1]==0 and fft_resultado[i+1]==0 and fft_resultado[i]<=0.05*pico_maximo:
        #     fft_resultado[i]=0
        # Atualizar a coluna no DataFrame filtrado
        df_filtrado[coluna] = np.real(np.fft.ifft(fft_resultado)*N)

    return df_filtrado

def comparativo_tempo_freq(dataset1, dataset2, title='Comparação do Domínio do Tempo e Frequência'):
    fig, axs = plt.subplots(3, 4, figsize=(20, 15))
    fig.suptitle(title, fontsize=16)

    N = len(dataset1.index)
    tempo = np.linspace(0, 10, N)
    freq = np.fft.fftfreq(N, 1/1000)

    colunas_aceleracao = [
        'Eixo_x', 'Eixo_y', 'Eixo_z'
    ]

    for i, coluna in enumerate(colunas_aceleracao):
        # Plotar no domínio do tempo para o Dataset 1
        axs[i, 0].plot(tempo, dataset1[coluna])
        axs[i, 0].set_title(f'Aceleração {coluna} - Original')
        axs[i, 0].set_xlabel('Tempo [s]')
        axs[i, 0].set_ylabel('Aceleração')

        # Plotar no domínio da frequência para o Dataset 1
        fft_result1 = np.abs(np.fft.fft(dataset1[coluna])) / N
        axs[i, 1].plot(freq[0:int(N/2)], fft_result1[:N//2], 'k')
        axs[i, 1].set_title(f'FFT da Aceleração {coluna} - Original')
        axs[i, 1].set_xlabel('Frequência [rad/s]')
        axs[i, 1].set_ylabel('Amplitude')

        # Plotar no domínio do tempo para o Dataset 2
        axs[i, 2].plot(tempo, dataset2[coluna])
        axs[i, 2].set_title(f'Aceleração {coluna} - Filtrado')
        axs[i, 2].set_xlabel('Tempo [s]')
        axs[i, 2].set_ylabel('Aceleração')

        # Plotar no domínio da frequência para o Dataset 2
        fft_result2 = np.abs(np.fft.fft(dataset2[coluna])) / N
        axs[i, 3].plot(freq[0:int(N/2)], fft_result2[:N//2], 'r')
        axs[i, 3].set_title(f'FFT da Aceleração {coluna} - Filtrado')
        axs[i, 3].set_xlabel('Frequência [rad/s]')
        axs[i, 3].set_ylabel('Amplitude')

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()
    print("Gráficos de Posição X Tempo e Amplitude X Frequência dos dois conjuntos de dados:")

def convert_df_values(df):

    # Converter para NumPy arrays
    df["Eixo_x"] = df["Eixo_x"].str.replace(',', '.').astype(float)
    df["Eixo_y"] = df["Eixo_y"].str.replace(',', '.').astype(float)
    df["Eixo_z"] = df["Eixo_z"].str.replace(',', '.').astype(float)
    df["Tempo[s]"] = df["Tempo[s]"].str.replace(',', '.').astype(float)

    return df

def calcular_features(data,fault):


    if "normal" in fault:
      n_janelas = 12
      margem_de_corte = 1000

    elif "unbalance" or "misalignment"  in fault:
      n_janelas = 1
      margem_de_corte = 250

    Np = 5000
    frequencia = 1000

    max_amplitudes = []
    medias = []
    desvios_padrao = []
    curtos = []
    cristas = []
    pico_a_pico_values = []
    media_ffts = []
    rms_values = []
    sqrt_amplitudes = []
    impulse_factors = []
    margin_factors = []
    rms_ffts = []
    peak_ffts = []
    freq_peak_ffts = []
    std_ffts = []
    distortions = []

    for i in range(n_janelas):
        janela = data[i * Np + margem_de_corte: (i + 1) * Np + margem_de_corte]

        max_amplitude = abs(janela).max()
        max_amplitudes.append(max_amplitude)

        media_tempo = janela.mean()
        medias.append(media_tempo)

        desvio_padrao_tempo = abs(janela).std() if janela.std() != 0 else 0
        desvios_padrao.append(desvio_padrao_tempo)

        curtose_tempo = janela.kurtosis()
        curtos.append(curtose_tempo)

        crista_tempo = abs(janela).max() / desvio_padrao_tempo
        cristas.append(crista_tempo)

        pico_a_pico_tempo = janela.max() - janela.min()
        pico_a_pico_values.append(pico_a_pico_tempo)

        fft_tempo = np.real(np.fft.fft(janela)) / len(janela)

        media_fft_tempo = abs(fft_tempo.mean())
        media_ffts.append(media_fft_tempo)

        rms_tempo = np.sqrt(np.mean(np.square(janela)))
        rms_values.append(rms_tempo)

        sqrt_amplitude_tempo = np.sqrt(max_amplitude)
        sqrt_amplitudes.append(sqrt_amplitude_tempo)

        impulse_factor_tempo = janela.max() / rms_tempo
        impulse_factors.append(impulse_factor_tempo)

        margin_factor_tempo = janela.max() / np.sqrt(np.mean(np.square(np.abs(janela))))
        margin_factors.append(margin_factor_tempo)

        rms_fft_tempo = np.sqrt(np.mean(np.square(np.abs(fft_tempo))))
        rms_ffts.append(rms_fft_tempo)

        peak_fft_tempo = np.max(np.abs(fft_tempo))
        peak_ffts.append(peak_fft_tempo)

        freq_peak_fft_tempo = np.argmax(np.abs(fft_tempo)) * (frequencia / len(janela))
        freq_peak_ffts.append(freq_peak_fft_tempo)

        distortion = np.sqrt(np.sum(np.abs(fft_tempo[2:]) ** 2)) / np.abs(fft_tempo[1])
        distortions.append(distortion)

        std_fft_tempo = np.abs(np.fft.fft(janela)).std()
        std_ffts.append(std_fft_tempo)

        distortion = np.sqrt(np.sum(np.diff(janela)**2)) / np.mean(np.abs(janela))
        distortions.append(distortion)

    novas_features = pd.DataFrame({
        'Amplitude Máxima': max_amplitudes,
        'Média': medias,
        'Desvio Padrão': desvios_padrao,
        'Fator de Curtose': curtos,
        'Fator de Crista': cristas,
        'Amplitude Pico a Pico': pico_a_pico_values,
        'media_fft': media_ffts,
        'Valor Quadrático Médio': rms_values,
        'Raiz Quadrada da Amplitude': sqrt_amplitudes,
        'Fator de Impulso': impulse_factors,
        'Fator de Margem': margin_factors,
        'Valor Quadrático Médio (FFT)': rms_ffts,
        'Valor de Pico (FFT)': peak_ffts,
        'Frequência do Pico (FFT)': freq_peak_ffts,
        'Distorção': distortion,
        'Desvio Padrão (FFT)': std_ffts
    })



    return novas_features

def criar_dataframe_com_features(df,fault):
    novas_features_x = calcular_features(df['Eixo_x'],fault).add_suffix('_x')
    novas_features_y = calcular_features(df['Eixo_y'],fault).add_suffix('_y')
    novas_features_z = calcular_features(df['Eixo_z'],fault).add_suffix('_z')

    df_gerado = pd.concat([novas_features_x, novas_features_y, novas_features_z], axis=1)

    return df_gerado

def add_labels(df, file, fault):

  if "misalignment" in fault:
    df['RPM'] = file.split('_')[0]
    df['faults'] = fault
    df['intensity'] = 0
    if "desal1" in file:
      df['intensity'] = 1


  if "normal" in fault:
    df['RPM'] = file.split('_')[0]
    df['faults'] = fault
    df['intensity'] = 0


  if "unbalance" in fault:
    df['RPM'] = file.split('_')[0]
    df['faults'] = fault
    df['intensity'] = 0

    string=file.split('_')[1][5:]

    for i in range(len(string)):
      if string[i] == 'a':
        df['intensity'] = string[i - 1]
      elif string[i] == 'b':
        df['intensity'] = string[i - 1]
      else:
        df['intensity'] =0
        df['intensity'] =0

  return df

def plot_fft_columnwise(df1, df2, df3):
    colunas_aceleracao = ['Eixo_x', 'Eixo_y', 'Eixo_z']

    plt.figure(figsize=(15, 5))
    for i, col in enumerate(colunas_aceleracao, 1):
        N1 = len(df1[col])
        f1 = np.fft.fftfreq(N1, 1 / 1000)
        fft_sinal1 = np.abs(np.fft.fft(df1[col])) * (1 / N1)

        N2 = len(df2[col])
        f2 = np.fft.fftfreq(N2, 1 / 1000)
        fft_sinal2 = np.abs(np.fft.fft(df2[col])) * (1 / N2)
        N3 = len(df3[col])
        f3 = np.fft.fftfreq(N3, 1 / 1000)
        fft_sinal3 = np.abs(np.fft.fft(df3[col])) * (1 / N3)

        plt.subplot(1, 3, i)
        plt.plot(f1[f1 > 0], fft_sinal1[f1 > 0], label='desalinhamento - 2100 RPM')
        plt.plot(f2[f2 > 0], fft_sinal2[f2 > 0], label='desalinhamento - 2100 RPM')
        plt.plot(f3[f3 > 0], fft_sinal3[f3 > 0], label='normal - 2100 RPM')

        plt.xlabel('Frequência (Hz)')
        plt.ylabel('Amplitude')
        plt.title(f'Espectro de Frequência - {col}')
        plt.legend()
        plt.xlim(0, 500)
        plt.xticks(np.arange(0, 501, 50))


    plt.tight_layout()
    plt.show()

path="/content/drive/MyDrive/Experimentos ML /"
# Lista os nomes dos arquivos na pasta

i=0

files = os.listdir(path)


for file in files:
  if "asc" not in file and "desc" not in file and "2100_desal1_pos2_" in file and i<=0:
    df1 = pd.read_table(path+file,skiprows=1)
    df1 = df1.drop("Sinal_4", axis=1)
    df1.columns = df1.columns.str.strip()
    df1 = convert_df_values(df1)
    # df1=filtrar_sinais(df1)
    print(file)
    print("")
    i+=1

i=0

for file in files:
  if "asc" not in file and "desc" not in file and "2100_desal1_pos2_" in file and i<=0:
    df2 = pd.read_table(path+file,skiprows=1)
    df2 = df2.drop("Sinal_4", axis=1)
    df2.columns = df2.columns.str.strip()
    df2 = convert_df_values(df2)
    # df2=filtrar_sinais(df2)
    print(file)
    print("")
    i+=1

i=0

for file in files:
  if "asc" not in file and "desc" not in file and "2100_normal_pos2_" in file and i<=0:
    df3 = pd.read_table(path+file,skiprows=1)
    df3 = df3.drop("Sinal_4", axis=1)
    df3.columns = df3.columns.str.strip()
    df3 = convert_df_values(df3)
    # df3=filtrar_sinais(df3)
    print(file)
    print("")
    i+=1

plot_fft_columnwise(df1,df2,df3)

plt.figure(figsize=(15, 5))

colunas_aceleracao = ['Eixo_x', 'Eixo_y', 'Eixo_z']

dff=filtrar_sinais(df3)

for i, col in enumerate(colunas_aceleracao, 1):
    N1 = len(dff[col])
    f1 = np.fft.fftfreq(N1, 1 / 1000)
    fft_sinal1 = np.abs(np.fft.fft(dff[col])) * (1 / N1)

    plt.subplot(1, 3, i)
    plt.plot(f1[f1 > 0], fft_sinal1[f1 > 0])

    plt.xlabel('Frequência (Hz)')
    plt.ylabel('Amplitude')
    plt.title(f'Espectro de Frequência - {col}')
    plt.legend()
    plt.xlim(0, 500)
    plt.xticks(np.arange(0, 501, 50))

plt.tight_layout()
plt.show()

path="/content/drive/MyDrive/Experimentos ML /"
# Lista os nomes dos arquivos na pasta

df_normal = pd.DataFrame()
df_unbalance = pd.DataFrame()
df_misalignment = pd.DataFrame()

files = os.listdir(path)
df_filtrado2 =  pd.DataFrame()

for file in files:
  if "asc" not in file and "desc" not in file and "normal" in file:
    df = pd.read_table(path+file,skiprows=1)
    df = df.drop("Sinal_4", axis=1)
    df.columns = df.columns.str.strip()
    df = convert_df_values(df)
    df_filtrado = filtrar_sinais(df)
    df_features = criar_dataframe_com_features(df_filtrado,fault="normal")
    df_normal = df_normal.append(add_labels(df_features, file,fault= "normal"), ignore_index=True)


for file in files:
  if "asc" not in file and "desc" not in file and "desba" in file:
    df = pd.read_table(path+file,skiprows=1)
    df = df.drop("Sinal_4", axis=1)
    df.columns = df.columns.str.strip()
    df = convert_df_values(df)
    df_filtrado = filtrar_sinais(df)
    df_features = criar_dataframe_com_features(df_filtrado,fault="unbalance")
    df_unbalance = df_unbalance.append(add_labels(df_features, file, fault= "unbalance"), ignore_index=True)

for file in files:
  if "asc" not in file and "desc" not in file and "desal" in file:
    df = pd.read_table(path+file,skiprows=1)
    df = df.drop("Sinal_4", axis=1)
    df.columns = df.columns.str.strip()
    df = convert_df_values(df)
    df_filtrado = filtrar_sinais(df)
    df_features = criar_dataframe_com_features(df_filtrado,fault="misalignment")
    df_misalignment = df_misalignment.append(add_labels(df_features, file, fault= "misalignment"), ignore_index=True)



df_experiments = pd.concat([df_normal,df_unbalance,df_misalignment])
df_experiments['RPM']= df_experiments['RPM'].astype(int)
df_experiments['intensity'] = pd.to_numeric(df_experiments['intensity'], errors='coerce')
df_experiments.loc[df_experiments['faults'] == 'unbalance', 'intensity'] *= 6.5
df_experiments.loc[df_experiments['faults'] == 'misalignment', 'intensity'] *= 0.005

df_experiments.info()

df_experiments

"""## Features Pre Processing"""

# Calcular a matriz de correlação
correlation_matrix = df_experiments.iloc[:, :-3].corr()

# Encontrar características com correlação superior a 0.8 ou inferior a -0.8
high_correlation_features = set()
for i in range(len(correlation_matrix.columns)):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > 0.8:
            feature_name = correlation_matrix.columns[i]
            high_correlation_features.add(feature_name)

# Remover características com alta correlação do DataFrame
df_no_high_correlation = df_experiments.drop(columns=high_correlation_features)

# Verificar as características remanescentes após a remoção
remaining_features = df_no_high_correlation.columns
print("Características remanescentes após remoção de alta correlação:")
print(remaining_features)

correlation_matrix = df_experiments.iloc[:, :-3].corr()

plt.figure(figsize=(12, 10))

sb.heatmap(correlation_matrix, cmap='coolwarm', cbar=True)

plt.title('Correlation Matrix')
plt.show()

correlation_matrix = df_no_high_correlation.iloc[:, :-3].corr()

plt.figure(figsize=(12, 10))

sb.heatmap(correlation_matrix, cmap='coolwarm', cbar=True)

plt.title('Correlation Matrix')
plt.show()

df_no_high_correlation

df_no_high_correlation.columns

sb.set(style="whitegrid")


numerical_columns = df_no_high_correlation.iloc[:, :-3].columns


num_columns = 3


num_rows = len(numerical_columns) // num_columns + (len(numerical_columns) % num_columns > 0)


fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 5*num_rows))
fig.subplots_adjust(hspace=0.5)


for i, column in enumerate(numerical_columns):
    row = i // num_columns
    col = i % num_columns
    ax = axes[row, col]


    sb.boxplot(x=df_no_high_correlation['faults'], y=df_no_high_correlation[column], ax=ax, palette="Set2")

    ax.set_title(column)
    ax.set_xlabel('Faults')

df = df_no_high_correlation.copy()

n_antigo = len(df)
def picos(x):
    a_max = np.abs(x.max() - x.mean())
    a99 = np.abs(np.percentile(x, 99) - x.mean())
    a01 = np.abs(np.percentile(x, 1) - x.mean())
    a_min = np.abs(x.min() - x.mean())
    teto = a_max / a99
    chao = a_min / a01
    return teto, chao


limiar_pico = 2
flag = 1
while flag:
    flag = 0
    for i in df.iloc[:, :-3].columns:
        teto, chao = picos(df[i])

        while teto > limiar_pico or chao > limiar_pico:
            flag = 1
            if teto > limiar_pico:
                df = df.drop(df[i].idxmax())
                teto, chao = picos(df[i])

            if chao > limiar_pico:
                df = df.drop(df[i].idxmin())
                teto, chao = picos(df[i])

n_novo = len(df)
df_no_outliers = df.copy()

print('Registros iniciais:', n_antigo)
print('Registros finais:', n_novo)
print('Outliers Encontrados:', n_antigo - n_novo)
print(f'Redução de {(100 * (n_antigo - n_novo) / n_antigo):.2f}%')

df_no_outliers

import seaborn as sb
import matplotlib.pyplot as plt


sb.set(style="whitegrid")

numerical_columns = df_no_high_correlation.iloc[:, :-3].columns

num_columns = 3

num_rows = len(numerical_columns) // num_columns + (len(numerical_columns) % num_columns > 0)

fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 5*num_rows))
fig.subplots_adjust(hspace=0.5)


for i, column in enumerate(numerical_columns):
    row = i // num_columns
    col = i % num_columns
    ax = axes[row, col]


    sb.distplot(df_no_high_correlation[column], ax=ax, kde=True, color="skyblue", hist_kws={"edgecolor": "white"})

    ax.set_title(column)
    ax.set_xlabel(column)


for i in range(len(numerical_columns), num_rows*num_columns):
    fig.delaxes(axes.flatten()[i])

plt.show()

"""## ML algorithms"""

categorical_columns = df_no_outliers.select_dtypes(include='object').columns

encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')

encoded_columns = pd.DataFrame(
    encoder.fit_transform(df_no_outliers[categorical_columns]),
    columns=encoder.get_feature_names_out(categorical_columns)
)

df_no_outliers_reset = df_no_outliers.reset_index(drop=True)

df_no_outliers_encoded = pd.concat([df_no_outliers_reset, encoded_columns], axis=1)
df_no_outliers_encoded = df_no_outliers_encoded.drop(columns=categorical_columns)

df_no_outliers_encoded

features_to_ignore = ['intensity']
X = df_no_outliers_encoded.drop(columns=features_to_ignore)
y = df_no_outliers_encoded[['faults_misalignment', 'faults_normal', 'faults_unbalance']]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

"""KNN"""

knn_classifier = KNeighborsClassifier(n_neighbors=5)


knn_classifier.fit(X_train, y_train)


predictions = knn_classifier.predict(X_test)


accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy: {accuracy:.2f}')

"""Randon Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


classifier_rf = RandomForestClassifier(max_depth=10, n_estimators=5, random_state=0)
classifier_rf.fit(X_train, y_train)

predictions = classifier_rf.predict(X_test)

accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy: {accuracy:.2f}')

"""Decision Tree

"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score



dt = DecisionTreeClassifier(max_depth=5, random_state=0)
dt.fit(X_train, y_train)


y_pred = dt.predict(X_test)


accuracy = accuracy_score(y_test, y_pred)


print("Accuracy:", accuracy)

"""LSTM"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from sklearn.metrics import mean_squared_error


model = Sequential()
model.add(LSTM(64, input_shape=(X_train.shape[1], 1)))
model.add(Dense(3, activation='softmax'))


model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])


history = model.fit(X_train, y_train, epochs=10, batch_size=32)


y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)


print("Mean squared error:", mse)

from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error


is_unbalance = (predictions[:, 2] == 1)
is_misalignment = (predictions[:, 0] == 1)


X_unbalance = X_test[is_unbalance]
y_unbalance = df_no_outliers_encoded.loc[X_unbalance.index, 'intensity']


X_misalignment = X_test[~is_misalignment]
y_misalignment = df_no_outliers_encoded.loc[X_misalignment.index, 'intensity']


regressor_unbalance = RandomForestRegressor(n_estimators=100, random_state=0)
regressor_unbalance.fit(X_unbalance, y_unbalance)


predicted_mass_rotor_a_unbalance = regressor_unbalance.predict(X_unbalance)


regressor_misalignment = RandomForestRegressor(n_estimators=100, random_state=0)
regressor_misalignment.fit(X_misalignment, y_misalignment)


predicted_misalignment = regressor_misalignment.predict(X_misalignment)


mse_unbalance = mean_squared_error(y_unbalance, predicted_mass_rotor_a_unbalance)
mse_misalignment = mean_squared_error(y_misalignment, predicted_misalignment)

print(f'Mean Squared Error for Unbalance: {mse_unbalance:.4f}')
print(f'Mean Squared Error for Misalignment: {mse_misalignment:.4f}')

predicted_mass_rotor_a_unbalance